The upsampling notebook contains code which was used for creating a custom dataset from the original training dataset, 
and features an edited version of the dataframe they generate and preprocess to fit this data.
after this version I realized it's easier to simply replace the test set with the custom validation set minus the labels,
and calculate the performance with the training labels. The custom dataset (and the original) is not in this git,
because it is far to large to upload, but it can be generated by running the upsampling notebook. 

the rest of the data, as well as the kernels used can be found by following below links:

kernels:
https://www.kaggle.com/shep312/deep-learning-in-tf-with-upsampling-lb-758
https://www.kaggle.com/rahullalu/hcdr-single-model-private-score-0-79167-catboost
https://www.kaggle.com/jsaguiar/lightgbm-7th-place-solution
https://www.kaggle.com/astrus/entity-embedding-neural-network-keras-lb-0-748

dataset:
https://www.kaggle.com/c/home-credit-default-risk/overview

finally, to generate the votes and plots, see the subComination notebook, which takes the submission files
generated by the kernels to calculate a soft-and hard vote, and generates/saves plots of both.
